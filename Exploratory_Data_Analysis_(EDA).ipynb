{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exploratory Data Analysis (EDA).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyONOb9p2TYomrK+87VViAGZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sanaz-salari/Exploratory-Data-Analysis-EDA/blob/main/Exploratory_Data_Analysis_(EDA).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dash"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_I8b6WadqCX",
        "outputId": "28dd5152-ca7b-46ca-d81e-24e757e0e796"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dash\n",
            "  Downloading dash-2.4.1-py3-none-any.whl (9.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.8 MB 18.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from dash) (5.5.0)\n",
            "Collecting dash-html-components==2.0.0\n",
            "  Downloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n",
            "Requirement already satisfied: Flask>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from dash) (1.1.4)\n",
            "Collecting dash-core-components==2.0.0\n",
            "  Downloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n",
            "Collecting flask-compress\n",
            "  Downloading Flask_Compress-1.12-py3-none-any.whl (7.9 kB)\n",
            "Collecting dash-table==5.0.0\n",
            "  Downloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.0.4->dash) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.0.4->dash) (1.0.1)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.0.4->dash) (2.11.3)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.0.4->dash) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=1.0.4->dash) (2.0.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly>=5.0.0->dash) (8.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from plotly>=5.0.0->dash) (1.15.0)\n",
            "Collecting brotli\n",
            "  Downloading Brotli-1.0.9-cp37-cp37m-manylinux1_x86_64.whl (357 kB)\n",
            "\u001b[K     |████████████████████████████████| 357 kB 50.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: brotli, flask-compress, dash-table, dash-html-components, dash-core-components, dash\n",
            "Successfully installed brotli-1.0.9 dash-2.4.1 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0 flask-compress-1.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_-Utfuqaq2c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import dash\n",
        "from dash import dcc\n",
        "from dash import html\n",
        "from dash.dependencies import Input, Output\n",
        "import plotly.express as px\n",
        "import plotly.figure_factory as ff\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "import sys\n",
        "np.set_printoptions(threshold=sys.maxsize)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "app = dash.Dash(__name__)\n",
        "\n",
        "df1 = pd.read_csv(\"simplyhired.csv\")\n",
        "df1.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
        "df1['jobtype'] = np.nan\n",
        "df2 = pd.read_csv(\"indeed_jobs.csv\")\n",
        "df2.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
        "df2['company'] = np.nan\n",
        "df2 = df2[['company', 'description', 'location', 'salary', 'title', 'jobtype']]\n",
        "df3 = pd.read_csv(\"flexjobs.csv\")\n",
        "df3.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
        "df3['company'] = np.nan\n",
        "df3 = df3[['company', 'description', 'location', 'salary', 'title', 'jobtype']]\n",
        "frames = [df1, df2, df3]\n",
        "df = pd.concat(frames)\n",
        "df.salary = df.salary.str.replace('$', '')\n",
        "df.salary = df.salary.str.replace(',', '')"
      ],
      "metadata": {
        "id": "qkmZOKK_a7PQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#title\n",
        "df.salary = df.salary.str.replace('Analyat', 'Analyst')\n",
        "df.loc[df['title'].str.contains('Data Scientist', case=False), 'title'] = 'Data Scientist'\n",
        "df.loc[df['title'].str.contains('Data Science', case=False), 'title'] = 'Data Scientist'\n",
        "df.loc[df['title'].str.contains('Machine Learning', case=False), 'title'] = 'Data Scientist'\n",
        "df.loc[df['title'].str.contains('Artificial Intelligence', case=False), 'title'] = 'Data Scientist'\n",
        "df.loc[df['title'].str.contains('ML'), 'title'] = 'Data Scientist'\n",
        "df.loc[df['title'].str.contains('AI'), 'title'] = 'Data Scientist'\n",
        "df.loc[df['title'].str.contains('Data Analyst', case=False), 'title'] = 'Data Analyst'\n",
        "df.loc[df['title'].str.contains('Data Analytics', case=False), 'title'] = 'Data Analyst'\n",
        "df.loc[df['title'].str.contains('Data & Analytics', case=False), 'title'] = 'Data Analyst'\n",
        "df.loc[df['title'].str.contains('Data Specialist', case=False), 'title'] = 'Data Analyst'\n",
        "df.loc[df['title'].str.contains('Data Engineer', case=False), 'title'] = 'Data Engineer'\n",
        "df.loc[df['title'].str.contains('Data Architect', case=False), 'title'] = 'Other Data Jobs'\n",
        "df.loc[df['title'].str.contains('Data Mining', case=False), 'title'] = 'Other Data Jobs'\n",
        "df.loc[df['title'].str.contains('Data Miner', case=False), 'title'] = 'Other Data Jobs'\n",
        "df.loc[df['title'].str.contains('Data Modeler', case=False), 'title'] = 'Other Data Jobs'\n",
        "df.loc[df['title'].str.contains('Data Quality', case=False), 'title'] = 'Other Data Jobs'\n",
        "df.loc[df['title'].str.contains('Data Manager', case=False), 'title'] = 'Other Data Jobs'\n",
        "df.loc[df['title'].str.contains('Big Data', case=False), 'title'] = 'Other Data Jobs'\n",
        "df.loc[df['title'].str.contains('Data Manager', case=False), 'title'] = 'Other Data Jobs'\n",
        "df.loc[df['title'].str.contains('Data Migration', case=False), 'title'] = 'Other Data Jobs'\n",
        "df.loc[df['title'].str.contains('Data Visualization', case=False), 'title'] = 'Other Data Jobs'\n",
        "df.loc[df['title'].str.contains('Statistician', case=False), 'title'] = 'Statistician'\n",
        "df.loc[df['title'].str.contains('Statistical', case=False), 'title'] = 'Statistician'\n",
        "df.loc[df['title'].str.contains('Mathematician', case=False), 'title'] = 'Mathematician'\n",
        "df.loc[df['title'].str.contains('Mathematical', case=False), 'title'] = 'Mathematician'\n",
        "df.loc[df['title'].str.contains('Marketing Manager', case=False), 'title'] = 'Marketing Manager'\n",
        "df.loc[df['title'].str.contains('Product Manager', case=False), 'title'] = 'Product Manager'\n",
        "df.loc[df['title'].str.contains('Python Developer', case=False), 'title'] = 'Software Developer'\n",
        "df.loc[df['title'].str.contains('Software Developer', case=False), 'title'] = 'Software Developer'\n",
        "df.loc[df['title'].str.contains('App Developer', case=False), 'title'] = 'Software Developer'\n",
        "df.loc[df['title'].str.contains('Mobile Developer', case=False), 'title'] = 'Software Developer'\n",
        "df.loc[df['title'].str.contains('Frontend Developer', case=False), 'title'] = 'Software Developer'\n",
        "df.loc[df['title'].str.contains('Web Applications Developer', case=False), 'title'] = 'Software Developer'\n",
        "df.loc[df['title'].str.contains('PHP Developer', case=False), 'title'] = 'Software Developer'\n",
        "df.loc[df['title'].str.contains('Full-Stack Developer', case=False), 'title'] = 'Software Developer'\n",
        "df.loc[df['title'].str.contains('Backend Developer', case=False), 'title'] = 'Software Developer'\n",
        "df.loc[df['title'].str.contains('Node.js Developer', case=False), 'title'] = 'Software Developer'\n",
        "df.loc[df['title'].str.contains('Bioinformatician', case=False), 'title'] = 'Bioinformatician'\n",
        "df.loc[df['title'].str.contains('Data', case=False) & df['title'].str.contains('Scientist', case=False), 'title'] = 'Data Scientist'\n",
        "df.loc[df['title'].str.contains('Data', case=False) & df['title'].str.contains('Science', case=False), 'title'] = 'Data Scientist'\n",
        "df.loc[df['title'].str.contains('Data', case=False) & df['title'].str.contains('Analyst', case=False), 'title'] = 'Data Analyst'\n",
        "df.loc[df['title'].str.contains('Data', case=False) & df['title'].str.contains('Analytics', case=False), 'title'] = 'Data Analyst'\n",
        "df.loc[df['title'].str.contains('Data', case=False) & df['title'].str.contains('Engineer', case=False), 'title'] = 'Data Engineer'\n",
        "df.loc[df['title'].str.contains('Data', case=False) & df['title'].str.contains('Architect', case=False), 'title'] = 'Other Data Jobs'\n",
        "df.loc[df['title'].str.contains('Data', case=False) & df['title'].str.contains('Mining', case=False), 'title'] = 'Other Data Jobs'\n",
        "df.loc[df['title'].str.contains('Data', case=False) & df['title'].str.contains('Miner', case=False), 'title'] = 'Other Data Jobs'\n",
        "df.loc[df['title'].str.contains('Data', case=False) & df['title'].str.contains('Quality', case=False), 'title'] = 'Other Data Jobs'\n",
        "df.loc[df['title'].str.contains('Data', case=False) & df['title'].str.contains('Consultant', case=False), 'title'] = 'Other Data Jobs'\n",
        "df.loc[df['title'].str.contains('Data', case=False) & df['title'].str.contains('Operations', case=False), 'title'] = 'Other Data Jobs'\n",
        "df.loc[df['title'].str.contains('Data', case=False) & df['title'].str.contains('Specialist', case=False), 'title'] = 'Other Data Jobs'\n",
        "df.loc[df['title'].str.contains('Data', case=False) & df['title'].str.contains('Manager', case=False), 'title'] = 'Data Manager'\n",
        "df.loc[df['title'].str.contains('Data', case=False) & df['title'].str.contains('Management', case=False), 'title'] = 'Data Manager'\n",
        "df.loc[df['title'].str.contains('Data', case=False) & df['title'].str.contains('Director', case=False), 'title'] = 'Data Manager'\n",
        "df.loc[df['title'].str.contains('Data', case=False) & df['title'].str.contains('Supervisor', case=False), 'title'] = 'Data Manager'\n",
        "df.loc[df['title'].str.contains('Data', case=False) & df['title'].str.contains('Associate', case=False), 'title'] = 'Data Manager'\n",
        "df.loc[df['title'].str.contains('Data', case=False) & df['title'].str.contains('Lead', case=False), 'title'] = 'Data Manager'\n",
        "df.loc[df['title'].str.contains('Data', case=False) & df['title'].str.contains('Mentor', case=False), 'title'] = 'Data Manager'\n",
        "df.loc[df['title'].str.contains('BI') & df['title'].str.contains('Developer', case=False), 'title'] = 'BI Developer'\n",
        "#df.loc[(df['title'].str.contains('Business Intelligence', case=False), 'title') and (df['title'].str.contains('Developer', case=False), 'title')] = 'BI Developer'"
      ],
      "metadata": {
        "id": "KYBsZiCMbBsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "\n",
        "#remote - person\n",
        "df['jobtype'].fillna('In Person', inplace=True)\n",
        "df['Remote_InPerson'] = np.nan\n",
        "df['jobtype'].replace('100% Remote Job', 'Remote')\n",
        "df.loc[df.jobtype.isin(['Remote', 'Temporarily Remote', 'Partial Remote Job',\n",
        "                       'Option for Remote Job', 'Remote - During Pandemic Job']), 'Remote_InPerson'] = 'Remote'\n",
        "df.loc[df.jobtype.isin(['In Person', 'Flexible Schedule Job', 'Full-Time', 'Temporary Job',\n",
        "                       'Part-Time', 'Freelance Job']), 'Remote_InPerson'] = 'In Person'\n",
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "df.drop_duplicates(inplace=True)\n",
        "df.reset_index(inplace=True)\n",
        "us_state_to_abbrev = {\n",
        "    \"Alabama\": \"AL\",\n",
        "    \"Alaska\": \"AK\",\n",
        "    \"Arizona\": \"AZ\",\n",
        "    \"Arkansas\": \"AR\",\n",
        "    \"California\": \"CA\",\n",
        "    \"Colorado\": \"CO\",\n",
        "    \"Connecticut\": \"CT\",\n",
        "    \"Delaware\": \"DE\",\n",
        "    \"Florida\": \"FL\",\n",
        "    \"Georgia\": \"GA\",\n",
        "    \"Hawaii\": \"HI\",\n",
        "    \"Idaho\": \"ID\",\n",
        "    \"Illinois\": \"IL\",\n",
        "    \"Indiana\": \"IN\",\n",
        "    \"Iowa\": \"IA\",\n",
        "    \"Kansas\": \"KS\",\n",
        "    \"Kentucky\": \"KY\",\n",
        "    \"Louisiana\": \"LA\",\n",
        "    \"Maine\": \"ME\",\n",
        "    \"Maryland\": \"MD\",\n",
        "    \"Massachusetts\": \"MA\",\n",
        "    \"Michigan\": \"MI\",\n",
        "    \"Minnesota\": \"MN\",\n",
        "    \"Mississippi\": \"MS\",\n",
        "    \"Missouri\": \"MO\",\n",
        "    \"Montana\": \"MT\",\n",
        "    \"Nebraska\": \"NE\",\n",
        "    \"Nevada\": \"NV\",\n",
        "    \"New Hampshire\": \"NH\",\n",
        "    \"New Jersey\": \"NJ\",\n",
        "    \"New Mexico\": \"NM\",\n",
        "    \"New York\": \"NY\",\n",
        "    \"North Carolina\": \"NC\",\n",
        "    \"North Dakota\": \"ND\",\n",
        "    \"Ohio\": \"OH\",\n",
        "    \"Oklahoma\": \"OK\",\n",
        "    \"Oregon\": \"OR\",\n",
        "    \"Pennsylvania\": \"PA\",\n",
        "    \"Rhode Island\": \"RI\",\n",
        "    \"South Carolina\": \"SC\",\n",
        "    \"South Dakota\": \"SD\",\n",
        "    \"Tennessee\": \"TN\",\n",
        "    \"Texas\": \"TX\",\n",
        "    \"Utah\": \"UT\",\n",
        "    \"Vermont\": \"VT\",\n",
        "    \"Virginia\": \"VA\",\n",
        "    \"Washington\": \"WA\",\n",
        "    \"West Virginia\": \"WV\",\n",
        "    \"Wisconsin\": \"WI\",\n",
        "    \"Wyoming\": \"WY\",\n",
        "    \"District of Columbia\": \"DC\",\n",
        "    \"American Samoa\": \"AS\",\n",
        "    \"Guam\": \"GU\",\n",
        "    \"Northern Mariana Islands\": \"MP\",\n",
        "    \"Puerto Rico\": \"PR\",\n",
        "    \"United States Minor Outlying Islands\": \"UM\",\n",
        "    \"U.S. Virgin Islands\": \"VI\",\n",
        "}"
      ],
      "metadata": {
        "id": "IJLxsbpjbCY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for index, row in df.iterrows():\n",
        "    #salary\n",
        "    if row.salary is not np.nan:\n",
        "        x = str(row.salary).split()\n",
        "        #print(x)\n",
        "        time_interval = 0\n",
        "        first_value = 0\n",
        "        second_value = 0\n",
        "        yearly_salary = 0\n",
        "        for i in x:\n",
        "            if i.replace('.', '').isnumeric():\n",
        "                if first_value == 0:\n",
        "                    first_value = float(i)\n",
        "                else:\n",
        "                    second_value = float(i)\n",
        "            else:\n",
        "                if i == 'hour':\n",
        "                    time_interval = 2080\n",
        "                elif i == 'day':\n",
        "                    time_interval = 261\n",
        "                elif i == 'year':\n",
        "                    time_interval = 1\n",
        "\n",
        "        if time_interval == 0:\n",
        "            if first_value > 1000:\n",
        "                time_interval = 1\n",
        "            elif first_value > 200:\n",
        "                time_interval = 261\n",
        "            else:\n",
        "                time_interval = 2080\n",
        "        if first_value > 0:\n",
        "            if second_value > 0:\n",
        "                yearly_salary = (second_value + first_value) / 2 * time_interval\n",
        "            else:\n",
        "                yearly_salary = first_value * time_interval\n",
        "        else:\n",
        "            yearly_salary = np.nan\n",
        "        #print(yearly_salary)\n",
        "        df.at[index, 'salary'] = yearly_salary\n",
        "\n",
        "    #location\n",
        "    State_Code = np.nan\n",
        "    x = str(row.location)\n",
        "    x = x.replace(' ', '')\n",
        "    for i in range(10):\n",
        "        x = x.replace(str(i), '')\n",
        "    x = x.replace('+locations', '')\n",
        "    x = x.replace('+location', '')\n",
        "    x = x.replace(',orUSNational', '')\n",
        "    x = x.replace('USNational', '')\n",
        "    if(x.count(',')) == 1:\n",
        "        x2 = x.split(',')\n",
        "        if len(x2[1]) == 2:\n",
        "            State_Code = x2[1]\n",
        "        elif len(x2[1]) == 3:\n",
        "            State_Code = str(x2[1])[:2]\n",
        "    else:\n",
        "        if x in us_state_to_abbrev.keys():\n",
        "            State_Code = us_state_to_abbrev[x]\n",
        "        elif x in us_state_to_abbrev.values():\n",
        "            State_Code = x\n",
        "        else:\n",
        "            State_Code = str(row.location)\n",
        "    df.at[index, 'location'] = State_Code"
      ],
      "metadata": {
        "id": "iUHuN1PDbC4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "#fig 2\n",
        "df_Salary_JobTitle = df[df['salary'].notna()]\n",
        "df_Salary_JobTitle = df_Salary_JobTitle.groupby('title', as_index=False)['salary'].mean().nlargest(10, 'salary')\n",
        "fig2 = px.bar(df_Salary_JobTitle, x=\"title\", y=\"salary\") #, color=\"City\", barmode=\"group\"\n",
        "'''\n",
        "\n",
        "#fig 3\n",
        "df_jobtype = df[df['jobtype'].notna()]\n",
        "df_jobtype = df_jobtype.groupby(['jobtype', 'Remote_InPerson'], as_index=False)['title'].count()\n",
        "fig3 = px.sunburst(df_jobtype, path=['Remote_InPerson', 'jobtype'], values='title',\n",
        "                  color='title', hover_data=['title'],\n",
        "                  color_continuous_scale='RdBu',\n",
        "                  color_continuous_midpoint=np.average(df_jobtype['title'], weights=df_jobtype['title']))\n",
        "\n",
        "#fig 4\n",
        "df_Salary_Variation = df[df['salary'].notna()]\n",
        "df_Salary_Variation = df_Salary_Variation[df['title'].isin(['Data Scientist', 'Data Engineer', 'Data Engineer', 'Data Manager', 'Other Data Jobs', 'Software Developer'])]\n",
        "fig4 = px.box(df_Salary_Variation, x=\"title\", y=\"salary\")\n"
      ],
      "metadata": {
        "id": "6bLot3clcpsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app.layout = html.Div(children=[\n",
        "    html.Div(children=[\n",
        "        html.H1(children='DSE 6000 Web App project'),\n",
        "        html.H2(children='Job Data'),\n",
        "    ], style={'text-align': 'center', 'background-color':'lavender', 'margin':'10px 3px 3px 3px', 'padding':'3px 3px 3px 3px'}),\n",
        "    html.Div(children=[\n",
        "    html.H3(children='Count of Job Titles across states'),\n",
        "    ] , style={'background-color':'cornflowerblue', 'margin':'10px 3px 3px 3px', 'padding':'3px 3px 3px 3px'}),\n",
        "    html.Div(children=[\n",
        "        html.Label('Job Title'),\n",
        "        dcc.Dropdown(\n",
        "            options=[\n",
        "                {'label': 'All', 'value': 'All'},\n",
        "                {'label': 'Data Scientist', 'value': 'Data Scientist'},\n",
        "                {'label': 'Data Analyst', 'value': 'Data Analyst'},\n",
        "                {'label': 'Data Engineer', 'value': 'Data Engineer'},\n",
        "                {'label': 'Data Manager', 'value': 'Data Manager'},\n",
        "                {'label': 'Other Data Jobs', 'value': 'Other Data Jobs'},\n",
        "                {'label': 'Software Developer', 'value': 'Software Developer'}\n",
        "            ],\n",
        "            value='MTL', id='Indicator_id',\n",
        "        )\n",
        "    ], style={'width':'40%'}),\n",
        "    dcc.Graph(id='JobTitle_Count'),\n",
        "    html.Div(children=[\n",
        "        html.H4(children='Knowing about the status of each job title in each state is of the significant importance for one who seeks a job. As we see among all of the states, data-related jobs has the highest numebr in California and New York, respectively.')\n",
        "    ], style={'background-color': 'mintcream', 'margin': '3px 3px 3px 3px', 'padding': '3px 3px 3px 3px'}),\n",
        "    html.Div(children=[\n",
        "    html.H3(children='Job Types'),\n",
        "    ] , style={'background-color':'cornflowerblue', 'margin':'10px 3px 3px 3px', 'padding':'3px 3px 3px 3px'}),\n",
        "    dcc.Graph(id='Job_Types', figure=fig3),\n",
        "    html.Div(children=[\n",
        "        html.H4(children='Job types including remote and in person can give a view that there still most of the jobs are done in person.')\n",
        "    ], style={'background-color': 'mintcream', 'margin': '3px 3px 3px 3px', 'padding': '3px 3px 3px 3px'}),\n",
        "    html.Div(children=[\n",
        "        html.H3(children='Salary Variation'),\n",
        "    ] , style={'background-color':'cornflowerblue', 'margin':'10px 3px 3px 3px', 'padding':'3px 3px 3px 3px'}),\n",
        "    dcc.Graph(id='Salary_Variation', figure=fig4),\n",
        "    html.Div(children=[\n",
        "        html.H4(children='Salary comparison between hot job titles related to data including minimum and maximum salary values show that data scientist has a higher salary.')\n",
        "    ], style={'background-color': 'mintcream', 'margin': '3px 3px 3px 3px', 'padding': '3px 3px 3px 3px'}),\n",
        "    html.Div(children=[\n",
        "        html.H3(children='Jobs in states'),\n",
        "    ] , style={'background-color':'cornflowerblue', 'margin':'10px 3px 3px 3px', 'padding':'3px 3px 3px 3px'}),\n",
        "    dcc.RadioItems(\n",
        "        id='states',\n",
        "        options=[\n",
        "            {'label': 'California', 'value': 'CA'},\n",
        "            {'label': 'New York', 'value': 'NY'},\n",
        "            {'label': 'Virginia', 'value': 'VA'},\n",
        "            {'label': 'Massachusetts', 'value': 'MA'},\n",
        "            {'label': 'Texas', 'value': 'TX'},\n",
        "        ],\n",
        "        value='Linear',\n",
        "        labelStyle={'display': 'inline-block'}\n",
        "    ),\n",
        "    html.Div(children=[\n",
        "        html.H4(children='Companies'),\n",
        "        dcc.Graph(id='Jobs_In_States_Com')\n",
        "    ], style={'width':'40%', 'float': 'left', 'text-align': 'center'}),\n",
        "    html.Div(children=[\n",
        "        html.H4(children='TOP 5 Job Titles'),\n",
        "        dcc.Graph(id='Jobs_In_States')\n",
        "    ], style={'width':'40%', 'float': 'right', 'text-align': 'center'}),\n",
        "    html.Div(children=[\n",
        "        html.H4(children='Job Type'),\n",
        "        dcc.Graph(id='Jobs_In_States_R_IP')\n",
        "    ], style={'width':'40%', 'float': 'left', 'text-align': 'center'}),\n",
        "    html.Div(children=[\n",
        "        html.H4(children='Job Salaries'),\n",
        "        dcc.Graph(id='Jobs_In_States_Payment')\n",
        "    ], style={'width':'40%', 'float': 'right', 'text-align': 'center'}),\n",
        "    html.Div(children=[\n",
        "        html.H4(children='Different companies in 5 considered states have various number of hired data related  jobs. But among all these jobs, data scientists job is the most popular job.It is interesting that data engineers have the largest income in Virginia, much more than maximum income earned by a data scientist.')\n",
        "    ], style={'background-color': 'mintcream', 'margin': '3px 3px 3px 3px', 'padding': '3px 3px 3px 3px', 'float': 'right'})\n",
        "], style={'font-family': 'Andale Mono, monospace'})\n",
        "@app.callback(\n",
        "    Output('JobTitle_Count', 'figure'),\n",
        "    Input('Indicator_id', 'value'))"
      ],
      "metadata": {
        "id": "d-B9oUqYc2Hf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_figure1(selected_Indicator):\n",
        "    if selected_Indicator == 'All':\n",
        "        df_JobTitle_Count = df.groupby('location', as_index=False)['title'].count()\n",
        "    else:\n",
        "        df_JobTitle_Count = df[df['title'] == selected_Indicator].groupby('location', as_index=False)['title'].count()\n",
        "    fig = px.choropleth(df_JobTitle_Count, locationmode=\"USA-states\", scope=\"usa\", locations=\"location\", color=\"title\", hover_name=\"title\",\n",
        "                        color_continuous_scale=px.colors.sequential.haline)\n",
        "    fig.update_layout(transition_duration=500)\n",
        "    return fig\n",
        "\n",
        "@app.callback(\n",
        "    Output('Jobs_In_States', 'figure'),\n",
        "    Input('states', 'value'))\n",
        "def update_figure5(states):\n",
        "    df_Jobs_In_States = df[df['location'] == states].groupby('title', as_index=False)['jobtype'].count().nlargest(5,'jobtype')\n",
        "    fig5 = px.bar(df_Jobs_In_States, x=\"title\", y=\"jobtype\")\n",
        "    fig5.update_layout(transition_duration=500)\n",
        "    return fig5\n",
        "\n",
        "@app.callback(\n",
        "    Output('Jobs_In_States_R_IP', 'figure'),\n",
        "    Input('states', 'value'))\n",
        "def update_figure5(states):\n",
        "    df_Jobs_In_States_R_IP = df[df['location'] == states].groupby('Remote_InPerson', as_index=False)['jobtype'].count()\n",
        "    fig6 = px.pie(df_Jobs_In_States_R_IP, values='jobtype', names='Remote_InPerson')\n",
        "    fig6.update_layout(transition_duration=500)\n",
        "    return fig6\n",
        "\n",
        "@app.callback(\n",
        "    Output('Jobs_In_States_Com', 'figure'),\n",
        "    Input('states', 'value'))\n",
        "def update_figure5(states):\n",
        "    df_Jobs_In_States_Com = df[df['location'] == states].groupby('company', as_index=False)['jobtype'].count().nlargest(10,'jobtype')\n",
        "    df_Jobs_In_States_Com.columns = df_Jobs_In_States_Com.columns.str.replace('jobtype', 'Count of Jobs')\n",
        "    fig7 = ff.create_table(df_Jobs_In_States_Com)\n",
        "    fig7.update_layout(transition_duration=500)\n",
        "    return fig7\n",
        "\n",
        "@app.callback(\n",
        "    Output('Jobs_In_States_Payment', 'figure'),\n",
        "    Input('states', 'value'))\n",
        "def update_figure5(states):\n",
        "    df_Jobs_In_States_Salary_Variation = df[df['salary'].notna()]\n",
        "    df_Jobs_In_States_Salary_Variation = df_Jobs_In_States_Salary_Variation[df_Jobs_In_States_Salary_Variation['title'].isin(['Data Scientist', 'Data Engineer', 'Data Engineer', 'Data Manager', 'Other Data Jobs', 'Software Developer'])]\n",
        "    df_Jobs_In_States_Salary_Variation = df_Jobs_In_States_Salary_Variation[df_Jobs_In_States_Salary_Variation['location'] == states]\n",
        "    fig8 = px.box(df_Jobs_In_States_Salary_Variation, x=\"title\", y=\"salary\")\n",
        "    fig8.update_layout(transition_duration=500)\n",
        "    return fig8\n",
        "if __name__ == '__main__':\n",
        "    app.run_server(debug=True)"
      ],
      "metadata": {
        "id": "9dYsYptxc9cE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}